{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63d434c6-a45f-4dc6-80a5-b15ae9f4a2a0",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/pavansanagapati/ensemble-learning-techniques-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "465c5008-61e1-497b-b0c0-267be6a13720",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e47ac78c-f9a5-45ca-aff5-6e075b9a75a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "iris = load_iris() \n",
    "X = iris.data[:, :4] \n",
    "Y = iris.target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8497341b-500a-4848-810b-4a8c34312f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a37d1ab-e04d-4aec-9e42-5f6f513b7853",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size = 0.20,random_state = 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60699b23-11a7-4356-a069-b4677bb21ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = [] \n",
    "estimator.append(('LR',LogisticRegression(solver ='lbfgs',multi_class ='multinomial',max_iter = 200))) \n",
    "estimator.append(('SVC', SVC(gamma ='auto', probability = True))) \n",
    "estimator.append(('DTC', DecisionTreeClassifier())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb4faf49-71ef-4b69-8733-69d05f707284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting Score 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "hard_voting = VotingClassifier(estimators = estimator, voting ='soft') \n",
    "hard_voting.fit(X_train, y_train) \n",
    "y_pred = hard_voting.predict(X_test)   \n",
    "# accuracy_score metric to predict Accuracy \n",
    "score = accuracy_score(y_test, y_pred) \n",
    "print(\"Hard Voting Score\", score) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90207e64-69b8-48ce-9cf6-7973611cc555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 1, 1, 0, 1, 2, 1, 1, 1,\n",
       "       2, 1, 1, 0, 0, 2, 0, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8cc40ad3-4686-4c5b-a71c-ed6bcc486d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 1, 1, 0, 1, 2, 1, 2, 1,\n",
       "       2, 1, 1, 0, 0, 2, 0, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee6c8163-6daa-4748-8b1c-7e2f230f325a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbce4718-56cf-4f53-8597-fe2e7baa4d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9666666666666667\n",
      "SVC Accuracy: 0.9666666666666667\n",
      "Decision Tree Accuracy: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming you have already loaded X and y from the Iris dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=2)\n",
    "\n",
    "# Define the individual estimators\n",
    "estimator_lr = LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=200)\n",
    "estimator_svc = SVC(gamma='auto', probability=True)\n",
    "estimator_dtc = DecisionTreeClassifier()\n",
    "\n",
    "# Train each individual estimator\n",
    "estimator_lr.fit(X_train, y_train)\n",
    "estimator_svc.fit(X_train, y_train)\n",
    "estimator_dtc.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for each estimator\n",
    "y_pred_lr = estimator_lr.predict(X_test)\n",
    "y_pred_svc = estimator_svc.predict(X_test)\n",
    "y_pred_dtc = estimator_dtc.predict(X_test)\n",
    "\n",
    "# Calculate accuracy for each estimator\n",
    "score_lr = accuracy_score(y_test, y_pred_lr)\n",
    "score_svc = accuracy_score(y_test, y_pred_svc)\n",
    "score_dtc = accuracy_score(y_test, y_pred_dtc)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", score_lr)\n",
    "print(\"SVC Accuracy:\", score_svc)\n",
    "print(\"Decision Tree Accuracy:\", score_dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2df2fd9-e445-4be1-bb2c-ffa482b9307f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class stacking(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self,mod,meta_model):\n",
    "        self.mod = mod\n",
    "        self.meta_model = meta_model\n",
    "        self.kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        self.saved_model = [list() for i in self.mod]\n",
    "        oof_train = np.zeros((X.shape[0], len(self.mod)))\n",
    "        \n",
    "        for i,model in enumerate(self.mod):\n",
    "            for train_index, val_index in self.kf.split(X,y):\n",
    "                renew_model = clone(model)\n",
    "                renew_model.fit(X[train_index], y[train_index])\n",
    "                self.saved_model[i].append(renew_model)\n",
    "                oof_train[val_index,i] = renew_model.predict(X[val_index])\n",
    "        \n",
    "        self.meta_model.fit(oof_train,y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self,X):\n",
    "        whole_test = np.column_stack([np.column_stack(model.predict(X) for model in single_model).mean(axis=1) \n",
    "                                      for single_model in self.saved_model]) \n",
    "        return self.meta_model.predict(whole_test)\n",
    "    \n",
    "    def get_oof(self,X,y,test_X):\n",
    "        oof = np.zeros((X.shape[0],len(self.mod)))\n",
    "        test_single = np.zeros((test_X.shape[0],5))\n",
    "        test_mean = np.zeros((test_X.shape[0],len(self.mod)))\n",
    "        for i,model in enumerate(self.mod):\n",
    "            for j, (train_index,val_index) in enumerate(self.kf.split(X,y)):\n",
    "                clone_model = clone(model)\n",
    "                clone_model.fit(X[train_index],y[train_index])\n",
    "                oof[val_index,i] = clone_model.predict(X[val_index])\n",
    "                test_single[:,j] = clone_model.predict(test_X)\n",
    "            test_mean[:,i] = test_single.mean(axis=1)\n",
    "        return oof, test_mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
